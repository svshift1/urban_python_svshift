{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvFk+ZAzmVy+DRJdL0SdxZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/svshift1/urban_python_svshift/blob/main/module_15/module_15_2_%D0%98%D1%81%D1%82%D0%BE%D1%80%D0%B8%D1%8F_%D0%B8_%D0%A0%D0%B0%D0%B7%D0%B2%D0%B8%D1%82%D0%B8%D0%B5_%D0%98%D0%98_%D0%94_%D0%97_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Первая цифровая и аналоговая реализация математической модели нейрона - перцептрон Розенблата.\n",
        "\n",
        "Реализуем операцию 2-И-не -- реализуемую аппаратно как двухэмиттерный транзистор на базе которого можно реализовать всё остальное."
      ],
      "metadata": {
        "id": "HUHTZ0_l_-C1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GywwB9Ig_2kn",
        "outputId": "f499ae0a-858e-4886-c226-5f2a34706257"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0] -> 1\n",
            "[0 1] -> 1\n",
            "[1 0] -> 1\n",
            "[1 1] -> 0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Функция активации (шаговая функция)\n",
        "def step_function(x):\n",
        "    return np.where(x >= 0, 1, 0)\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, input_size, learning_rate=0.01, epochs=1000):\n",
        "        self.W = np.zeros(input_size + 1)\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "\n",
        "    def predict(self, x):\n",
        "        return step_function(np.dot(self.W, x))\n",
        "\n",
        "    def train(self, X, y):\n",
        "        for _ in range(self.epochs):\n",
        "            for xi, target in zip(X, y):\n",
        "                xi = np.insert(xi, 0, 1)  # Вставка смещения (bias)\n",
        "                prediction = self.predict(xi)\n",
        "                self.W += self.learning_rate * (target - prediction) * xi\n",
        "\n",
        "# Данные для обучения (И, ИЛИ)\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([1, 1, 1, 0])  # Операция И-Не\n",
        "\n",
        "perceptron = Perceptron(input_size=2)\n",
        "perceptron.train(X, y)\n",
        "\n",
        "# Тестирование\n",
        "for xi in X:\n",
        "    xi_with_bias = np.insert(xi, 0, 1)  # Вставка смещения (bias) для тестирования\n",
        "    print(f\"{xi} -> {perceptron.predict(xi_with_bias)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "попробуем импликацию:\n"
      ],
      "metadata": {
        "id": "TaCIIXKGBmV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Данные для обучения (И, ИЛИ)\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([1, 1, 0, 1])  # Операция X --> Y\n",
        "\n",
        "perceptron = Perceptron(input_size=2)\n",
        "perceptron.train(X, y)\n",
        "\n",
        "# Тестирование\n",
        "for xi in X:\n",
        "    xi_with_bias = np.insert(xi, 0, 1)  # Вставка смещения (bias) для тестирования\n",
        "    print(f\"{xi} -> {perceptron.predict(xi_with_bias)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQKJoncrBqRG",
        "outputId": "2cbe9c64-b6ee-4b62-e2b1-3df14ca0868a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0] -> 1\n",
            "[0 1] -> 1\n",
            "[1 0] -> 0\n",
            "[1 1] -> 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "А теперь XOR --\n",
        "читал, что ее реально реализовать одним перцептроном с двумя входами+биасом и хитрой активаторной функцией - полиномиальная (просто к весам добавляются коэффициенты этого полинома) + сигмоида -- такой перцептрон будет делить плосколсть на параллельные полосы"
      ],
      "metadata": {
        "id": "WeAA07daB-hu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([0, 1, 1, 0])  # Операция X ^ Y\n",
        "\n",
        "for e in [1000, 10000, 20000, 50000] :\n",
        "  perceptron = Perceptron(input_size=2, epochs=e)\n",
        "  perceptron.train(X, y)\n",
        "\n",
        "  print(f'----------------\\nepochs: {e}')\n",
        "  # Тестирование\n",
        "  for xi in X:\n",
        "      xi_with_bias = np.insert(xi, 0, 1)  # Вставка смещения (bias) для тестирования\n",
        "      print(f\"   {xi} -> {perceptron.predict(xi_with_bias)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAXt7vPIB79R",
        "outputId": "f0ed74a5-b9af-40ca-ea0d-aad7744d16c9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------\n",
            "epochs: 1000\n",
            "   [0 0] -> 1\n",
            "   [0 1] -> 1\n",
            "   [1 0] -> 0\n",
            "   [1 1] -> 0\n",
            "----------------\n",
            "epochs: 10000\n",
            "   [0 0] -> 1\n",
            "   [0 1] -> 1\n",
            "   [1 0] -> 0\n",
            "   [1 1] -> 0\n",
            "----------------\n",
            "epochs: 20000\n",
            "   [0 0] -> 1\n",
            "   [0 1] -> 1\n",
            "   [1 0] -> 0\n",
            "   [1 1] -> 0\n",
            "----------------\n",
            "epochs: 50000\n",
            "   [0 0] -> 1\n",
            "   [0 1] -> 1\n",
            "   [1 0] -> 0\n",
            "   [1 1] -> 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "на выходе получилось тупо  not X[0]\n",
        "\n",
        "если учесть, что   x^y == (x|y)  &  !(x&y)   то понятно откуда берется оценка 5 слоев в mlp классификаторе. при этом 5000 итераций ему было мало\n",
        "пробовал при 4 слоях -- не всегда сходилась успешно даже на 50000 итерациях"
      ],
      "metadata": {
        "id": "d-r00A-2Db4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "import numpy as np\n",
        "\n",
        "# Данные для обучения (XOR)\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([0, 1, 1, 0])  # Операция XOR\n",
        "\n",
        "# Создание и обучение MLP-классификатора\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(4,), activation='relu', max_iter=50000, solver='adam')\n",
        "mlp.fit(X, y)\n",
        "\n",
        "# Тестирование\n",
        "for xi in X:\n",
        "    print(f\"{xi} -> {mlp.predict([xi])[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bH_b-g2DE9-4",
        "outputId": "320bb30f-e69d-4d45-a4a2-448b99c2670b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0] -> 0\n",
            "[0 1] -> 1\n",
            "[1 0] -> 1\n",
            "[1 1] -> 0\n"
          ]
        }
      ]
    }
  ]
}