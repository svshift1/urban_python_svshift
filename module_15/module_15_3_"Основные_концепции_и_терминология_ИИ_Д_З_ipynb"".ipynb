{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/svshift1/urban_python_svshift/blob/main/module_15/module_15_3_%22%D0%9E%D1%81%D0%BD%D0%BE%D0%B2%D0%BD%D1%8B%D0%B5_%D0%BA%D0%BE%D0%BD%D1%86%D0%B5%D0%BF%D1%86%D0%B8%D0%B8_%D0%B8_%D1%82%D0%B5%D1%80%D0%BC%D0%B8%D0%BD%D0%BE%D0%BB%D0%BE%D0%B3%D0%B8%D1%8F_%D0%98%D0%98_%D0%94_%D0%97_ipynb%22%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>ДЗ по сравнению  ML, DL, CNN</h1>\n"
      ],
      "metadata": {
        "id": "pKda_B4WMHXR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "установка пакетов"
      ],
      "metadata": {
        "id": "MfEUMtyoMchc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PDsO7Qm5e0px",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba55aa7b-be5d-4387-8459-d873e589002b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.1.24)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.14.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy pandas scikit-learn tensorflow keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Загрузка данных MNIST\n",
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "X, y = mnist.data / 255.0, mnist.target.astype(int)\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "GVcS--5BNLpX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "метод К-средних. вычисляются центры кластеров как ср. ар. k-ближайших соседей. классификация - по наибольшей близостик к тому или иному центру кластера. Процесс повторяется пока центры не \"устаканятся\". Хорошо работает когда кластеры - выпуклые множества (многоугольники), т.к. после самообучения получившиеся множества классификации будут в сущности диаграммами Вронского построенного на центрах кластеров. Для более сложных геометрий из ML-алгоритмов подойдут леса решающих деревьев и т.п.  "
      ],
      "metadata": {
        "id": "wt-6wVktMgGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Создание и обучение модели k-NN\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Прогнозирование на тестовой выборке\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "\n",
        "print(f'Accuracy of k-NN: {accuracy_knn:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWRPPouqMfmL",
        "outputId": "3c886199-d74a-41c3-f1e9-ae2670b56aaf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of k-NN: 0.9713\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задается MLP с входным слоем принимающим картинки 28x28, с двумя скрытыми слоями разных размерностейЮ и одним 10-мерным выходным, где картинка относится к тому или  иномму классу у того нейрона, у которого выходной сигнал будет максимальным. Преимущества по сравнению с предыдущим -- возможность описывать более сложные геометрии кластеров.  \n",
        "\n",
        "Недостаток при решении данной задачи -- в несколько раз б0льшее время на обучениие при сопоставимой точности."
      ],
      "metadata": {
        "id": "ke2Oo3R5OoEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "# Предобработка меток для MLP\n",
        "y_train_mlp = to_categorical(y_train, 10)\n",
        "y_test_mlp = to_categorical(y_test, 10)\n",
        "\n",
        "# Создание модели MLP\n",
        "model_mlp = Sequential([\n",
        "    Flatten(input_shape=(784,)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Компиляция и обучение модели MLP\n",
        "model_mlp.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_mlp.fit(X_train, y_train_mlp, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Оценка модели на тестовой выборке\n",
        "loss_mlp, accuracy_mlp = model_mlp.evaluate(X_test, y_test_mlp)\n",
        "\n",
        "print(f'Accuracy of MLP: {accuracy_mlp:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyeAk0GMMaCo",
        "outputId": "ea5f08eb-12e4-467b-dbc8-b918d39064a6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8677 - loss: 0.4618 - val_accuracy: 0.9552 - val_loss: 0.1508\n",
            "Epoch 2/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - accuracy: 0.9648 - loss: 0.1180 - val_accuracy: 0.9695 - val_loss: 0.1015\n",
            "Epoch 3/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9759 - loss: 0.0780 - val_accuracy: 0.9721 - val_loss: 0.0970\n",
            "Epoch 4/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9822 - loss: 0.0558 - val_accuracy: 0.9729 - val_loss: 0.0949\n",
            "Epoch 5/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9870 - loss: 0.0406 - val_accuracy: 0.9708 - val_loss: 0.0990\n",
            "Epoch 6/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9884 - loss: 0.0348 - val_accuracy: 0.9730 - val_loss: 0.0911\n",
            "Epoch 7/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.9914 - loss: 0.0256 - val_accuracy: 0.9681 - val_loss: 0.1195\n",
            "Epoch 8/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9924 - loss: 0.0219 - val_accuracy: 0.9734 - val_loss: 0.1036\n",
            "Epoch 9/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9940 - loss: 0.0180 - val_accuracy: 0.9740 - val_loss: 0.1050\n",
            "Epoch 10/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.9946 - loss: 0.0156 - val_accuracy: 0.9736 - val_loss: 0.1146\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9716 - loss: 0.1132\n",
            "Accuracy of MLP: 0.9724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Отличие сверточных сетей от предыдущего MLP -- в MLP выход с каждого i-го нейрона предыдущего слоя входит в i-й вход каждого нейрона из следующего. таким образом его выход влияет сразу на все нейроны следующего слоя.\n",
        "В сверточных сетях выход каждого предыдущего нейрона связан лишь с несколькими \"соседями\" из следующего слоя. Таким образом это позволяет проводить анализ участков сигналов или изображений а не всей картинки в целом.\n",
        "\n",
        "аналогия из анализа сигналов -- фурье-преобразование всего сигнала vs вейвлет преобразование.\n",
        "\n",
        "это может позволить не только классифицировать картинку в целом, но  и локализовать интересующие нас фичи.\n",
        "\n",
        "недостаток -- эта реализация обучается еще дольше т.к. слоёв больше\n",
        "результат: точность повысилась еще в 3 раза"
      ],
      "metadata": {
        "id": "KgrBOJMsRN4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout\n",
        "\n",
        "# Предобработка данных для CNN\n",
        "X_train_cnn = X_train.values.reshape(-1, 28, 28, 1)\n",
        "X_test_cnn = X_test.values.reshape(-1, 28, 28, 1)\n",
        "y_train_cnn = to_categorical(y_train, 10)\n",
        "y_test_cnn = to_categorical(y_test, 10)\n",
        "\n",
        "# Создание модели CNN\n",
        "model_cnn = Sequential([\n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Компиляция и обучение модели CNN\n",
        "model_cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_cnn.fit(X_train_cnn, y_train_cnn, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Оценка модели на тестовой выборке\n",
        "loss_cnn, accuracy_cnn = model_cnn.evaluate(X_test_cnn, y_test_cnn)\n",
        "\n",
        "print(f'Accuracy of CNN: {accuracy_cnn:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhLzrV9oRFXc",
        "outputId": "ffb9c698-c0e9-4715-b4a5-07684e90a47e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 42ms/step - accuracy: 0.8059 - loss: 0.5924 - val_accuracy: 0.9780 - val_loss: 0.0723\n",
            "Epoch 2/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 41ms/step - accuracy: 0.9633 - loss: 0.1240 - val_accuracy: 0.9859 - val_loss: 0.0464\n",
            "Epoch 3/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 40ms/step - accuracy: 0.9723 - loss: 0.0910 - val_accuracy: 0.9872 - val_loss: 0.0417\n",
            "Epoch 4/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 39ms/step - accuracy: 0.9784 - loss: 0.0713 - val_accuracy: 0.9868 - val_loss: 0.0389\n",
            "Epoch 5/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 39ms/step - accuracy: 0.9800 - loss: 0.0659 - val_accuracy: 0.9901 - val_loss: 0.0334\n",
            "Epoch 6/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 39ms/step - accuracy: 0.9824 - loss: 0.0587 - val_accuracy: 0.9900 - val_loss: 0.0333\n",
            "Epoch 7/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 37ms/step - accuracy: 0.9820 - loss: 0.0559 - val_accuracy: 0.9889 - val_loss: 0.0332\n",
            "Epoch 8/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 38ms/step - accuracy: 0.9853 - loss: 0.0470 - val_accuracy: 0.9908 - val_loss: 0.0316\n",
            "Epoch 9/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 39ms/step - accuracy: 0.9854 - loss: 0.0441 - val_accuracy: 0.9912 - val_loss: 0.0299\n",
            "Epoch 10/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 38ms/step - accuracy: 0.9865 - loss: 0.0432 - val_accuracy: 0.9908 - val_loss: 0.0310\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9904 - loss: 0.0329\n",
            "Accuracy of CNN: 0.9903\n"
          ]
        }
      ]
    }
  ]
}